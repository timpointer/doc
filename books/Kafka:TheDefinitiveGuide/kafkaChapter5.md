# Kafka 内部

## Ｃluster Membership
kafka使用zookeeper来维护当前broker集群的成员。每个成员都有一个ID，可以手动设置和自动分配。每当成员启动后会向zookeeper注册自己，创建一个ephemeral node（零时节点，zookeeper会管理其生命周期，如果成员失联，则自动删除）。其他kafka组件会订阅/brokers/ids下的消息。
如果你启动另一个同名的broker则会报错。
但broker关闭后，其他数据结构中关联的broker ID不会被删除，只要新的broker用的一样的ID就可以接替原来位置，继续工作。

### The Controller
kafka brokers中有一个节点担任管理者(controller)的角色，除了承担平常的职责外，还负责每个分片的leader的选择。通过zookeeper来确保每个时刻只有一个管理者。
当管理者失联后，每个节点接受到事件后，可以申请成为新的管理者。系统为管理者分片一个自增的编号，大家可以根据这个编号来忽略来自前管理者的消息。
当集群发生变化时，管理者有责任指定分片和副本配置。


## 副本
每个topic都会有许多分片，每个分片有多个副本，这些副本被分布到多个broker上，每个broker会存储成百上千个副本。
副本分为两种，一种是leader，一种是follower
leader负责该分片的所有对外请求。follower只从leader那里同步数据，当发生leader宕机的情况时，其中一个follower会被晋升为leader。

follower有两种状态，分为同步和非同步状态，当和leader之间数据同步延迟超过10秒(默认设置)，则被认定为非同步，非同步的follower不能晋升为leader。

## 请求处理
同一个客户端发送的请求会被broker顺序处理。客户端会发送metadata请求，来获取分片和broker之间的mapping信息。当客户端发送给请求到某个broker时，如果该broker没有对应分片的数据，则会返回错误，这些客户端需要更新自己的metadata缓存信息。

### 生产(produce)请求
根据ack参数来决定请求成功条件。当为0时，则立即返回。当为all时，等待所有副本确认同步后返回。kafka接收数据后会写入本地磁盘，在linux上,会先写入缓存区，此时并不能保证持久化成功。可靠性的保证主要依赖于副本。

### 读取(fetch)请求
消费者会发送请求说，请给我这个topic下第2分片的offsit53以后的数据。为了提高效率broker会累计一定量的消息再一起发送，但用户可以设置timeout，时间到了就会返回。消费者只会拿到被所有副本都已经同步了以后的消息，这样能确保持久性。


### 其他请求
kafka之前使用zookeeper记录offset，新版本改为使用一个特殊的topic来记录。kafka会不断新接口或扩展已有接口来提供新功能。最好先发布broker，再更新客户端，以避免版本兼容问题。

## 物理存储
最基本的存储单位是分片副本。分片不能在分割，必须存储在一个磁盘上。

### 分片分布
当你有一个topic，kafka必须先决定这些分片怎么在broker之间分配。假设我们有30个分片,6个broker
- 分配要平均，每个broker被分配5个分片
- 每个副本必须出现在不同的broker上
- 新版本broker拥有机架信息，让分片分布在不同的机架上，这样能避免机架宕机，而引起的分片不可用。
先遍历分配leader在不同的broker上，然后用leader加１或加２计算出其他副本分片在哪个broker上。
完成了分配以后，我们开始分配分片所在的文件夹，规则很简单，每次有新的分片，就添加到目前分片最少的那个文件夹下面。

### 文件管理
采用segment方式，比如设置为保留一星期的日志，按照一个文件包含一天消息来分割。这样只需要在超过7天以后直接删除最早一天的那个文件即可。这种批量操作的带来的性能的提升。